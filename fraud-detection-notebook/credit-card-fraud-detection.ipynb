{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = data[data['isFraud'] == 1]\n",
    "not_fraud = data[data['isFraud'] == 0]\n",
    "# Take a random sample of non fraud rows\n",
    "not_fraud_sample = not_fraud.sample(random_state=2, frac=.005)\n",
    "\n",
    "# Put it back together and shuffle\n",
    "df = pd.concat([not_fraud_sample,fraud])\n",
    "df = shuffle(df, random_state=2)\n",
    "\n",
    "# Remove a few columns (isFraud is the label column we'll use, not isFlaggedFraud)\n",
    "df = df.drop(columns=['nameOrig', 'nameDest', 'isFlaggedFraud'])\n",
    "# Adding transaction id to identify back after prediction\n",
    "df['transactionId'] = [str(uuid.uuid4()) for _ in range(len(df.index))]\n",
    "# Preview the updated dataset\n",
    "df.head()\n",
    "train_test_split = int(len(df) * .8)\n",
    "\n",
    "train_set = df[:train_test_split]\n",
    "test_set = df[train_test_split:]\n",
    "\n",
    "train_labels = train_set.pop('isFraud')\n",
    "test_labels = test_set.pop('isFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = tf.feature_column\n",
    "CATEGORICAL_COLUMNS = ['type']\n",
    "NUMERIC_COLUMNS = ['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "KEY_COLUMN = 'transactionId'\n",
    "def one_hot_cat_column(feature_name, vocab):\n",
    "    return tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocab))\n",
    "\n",
    "feature_columns = []\n",
    "\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "    vocabulary = train_set[feature_name].unique()\n",
    "    feature_columns.append(one_hot_cat_column(feature_name, vocabulary))\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "  feature_columns.append(tf.feature_column.numeric_column(feature_name,\n",
    "                                           dtype=tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = len(train_labels)\n",
    "def make_input_fn(X, y, n_epochs=None, shuffle=True):\n",
    "  def input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\n",
    "    if shuffle:\n",
    "      dataset = dataset.shuffle(NUM_EXAMPLES)\n",
    "    dataset = dataset.repeat(n_epochs)\n",
    "    dataset = dataset.batch(NUM_EXAMPLES)\n",
    "    return dataset\n",
    "  return input_fn\n",
    "\n",
    "# Define training and evaluation input functions\n",
    "train_input_fn = make_input_fn(train_set, train_labels)\n",
    "eval_input_fn = make_input_fn(test_set, test_labels, shuffle=False, n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpaq3xmjmx\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpaq3xmjmx', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1a7b996cd0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpaq3xmjmx', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f197c11a4d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "n_batches = 1\n",
    "model = tf.estimator.BoostedTreesClassifier(feature_columns,\n",
    "                                          n_batches_per_layer=n_batches)\n",
    "model = tf.contrib.estimator.forward_features(model,KEY_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpaq3xmjmx/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:loss = 0.6931538, step = 0\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 1.63577\n",
      "INFO:tensorflow:loss = 0.021963239, step = 99 (61.135 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpaq3xmjmx/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n"
     ]
    }
   ],
   "source": [
    "model.train(train_input_fn, max_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-22T19:30:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaq3xmjmx/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-22-19:30:35\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.9941228, accuracy_baseline = 0.8006753, auc = 0.9986786, auc_precision_recall = 0.99797404, average_loss = 0.024595074, global_step = 100, label/mean = 0.19932474, loss = 0.024595074, precision = 0.97424895, prediction/mean = 0.20004047, recall = 0.99686325\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /tmp/tmpaq3xmjmx/model.ckpt-100\n",
      "accuracy                  0.994123\n",
      "accuracy_baseline         0.800675\n",
      "auc                       0.998679\n",
      "auc_precision_recall      0.997974\n",
      "average_loss              0.024595\n",
      "label/mean                0.199325\n",
      "loss                      0.024595\n",
      "precision                 0.974249\n",
      "prediction/mean           0.200040\n",
      "recall                    0.996863\n",
      "global_step             100.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(eval_input_fn)\n",
    "print(pd.Series(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaq3xmjmx/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  1 Actual:  1\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  1 Actual:  1\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  1 Actual:  1\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n",
      "Predicted:  0 Actual:  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_dicts = list(model.predict(eval_input_fn))\n",
    "probabilities = pd.Series([pred['logistic'][0] for pred in pred_dicts])\n",
    "\n",
    "for i,val in enumerate(probabilities[:30]):\n",
    "  print('Predicted: ', round(val), 'Actual: ', test_labels.iloc[i])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP_PROJECT = '<project-id>'\n",
    "MODEL_BUCKET = '<bucket-name>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        'type': tf.placeholder(tf.string, [None]),\n",
    "        'step': tf.placeholder(tf.float32, [None]),\n",
    "        'amount': tf.placeholder(tf.float32, [None]),\n",
    "        'oldbalanceOrg': tf.placeholder(tf.float32, [None]),\n",
    "        'newbalanceOrig': tf.placeholder(tf.float32, [None]),\n",
    "        'oldbalanceDest': tf.placeholder(tf.float32, [None]),\n",
    "        'newbalanceDest': tf.placeholder(tf.float32, [None]),\n",
    "         KEY_COLUMN: tf.placeholder_with_default(tf.constant(['nokey']), [None])\n",
    "    }\n",
    "    features = {key: tf.expand_dims(tensor, -1)\n",
    "                for key, tensor in feature_placeholders.items()}\n",
    "    return tf.estimator.export.ServingInputReceiver(features,feature_placeholders)\n",
    "export_path = model.export_saved_model(\n",
    "    MODEL_BUCKET + '/explanations-with-key',\n",
    "    serving_input_receiver_fn=json_serving_input_fn\n",
    ").decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir $export_path --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'fraud_detection_with_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai-platform models create $MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'v1'\n",
    "!gcloud beta ai-platform versions create $VERSION \\\n",
    "--model $MODEL \\\n",
    "--origin $export_path \\\n",
    "--runtime-version 1.15 \\\n",
    "--framework TENSORFLOW \\\n",
    "--python-version 3.7 \\\n",
    "--machine-type n1-standard-4 \\\n",
    "--num-paths 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_indices = []\n",
    "\n",
    "for i,val in enumerate(test_labels):\n",
    "    if val == 1:\n",
    "        fraud_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_examples = 10\n",
    "import numpy as np \n",
    "\n",
    "def convert(o):\n",
    "    if isinstance(o, np.generic): return o.item()  \n",
    "    raise TypeError\n",
    "\n",
    "for i in range(num_test_examples):\n",
    "    test_json = {}\n",
    "    ex = test_set.iloc[fraud_indices[i]]\n",
    "    keys = ex.keys().tolist()\n",
    "    vals = ex.values.tolist()\n",
    "    for idx in range(len(keys)):\n",
    "        test_json[keys[idx]] = vals[idx]\n",
    "\n",
    "    print(test_json)\n",
    "    with open('data.txt', 'a') as outfile:\n",
    "        json.dump(test_json, outfile, default=convert)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai-platform predict --model $MODEL \\\n",
    "--version $VERSION \\\n",
    "--json-instances='data.txt' \\\n",
    "--signature-name='predict'"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
